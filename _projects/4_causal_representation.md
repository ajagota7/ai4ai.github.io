---
layout: page
title: Causal Representation Learning
description: Investigating causal structures for robust and generalizable AI
img: assets/img/6.jpg
importance: 4
category: research
related_publications: true
---

## Overview

Our causal representation learning research investigates how to discover and leverage causal structure in learned representations. This work aims to build AI systems that understand cause-and-effect relationships and can generalize more robustly to new environments.

## Key Research Questions

- How can we identify causal variables from observational data?
- What inductive biases encourage models to learn causal representations?
- How do causal representations improve out-of-distribution generalization?
- Can we transfer causal knowledge across different domains and tasks?

## Current Projects

### Causal Discovery in Neural Networks
Developing methods to discover causal graphs from the representations learned by deep neural networks, with applications to scientific discovery and decision-making.

### Disentangled Causal Representations
Creating architectures and training objectives that encourage learning of disentangled, causally-structured representations that separate independent factors of variation.

### Intervention-Based Learning
Using interventions and counterfactuals during training to guide models toward learning causal rather than merely correlational relationships.

### Transfer Learning via Causal Invariance
Leveraging causal invariances to improve transfer learning and domain adaptation, identifying which features remain stable across environments.

## Theoretical Foundations

- Structural Causal Models (SCMs)
- Identifiability theory
- Independent Component Analysis (ICA)
- Invariant risk minimization

## Applications

- Out-of-distribution robustness
- Scientific discovery and modeling
- Fairness and bias mitigation
- Sample-efficient transfer learning

---

*This is a template research area. Add your specific causal representation learning projects and publications.*
