---
layout: about
title: about
permalink: /
subtitle: Advancing AI Safety & Machine Learning Research

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <p>AI4AI Research Lab</p>
    <p>Contact: contact@ai4ai.org</p>
    <p>GitHub: @ajagota7</p>

selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

announcements:
  enabled: true # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: true
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---

Welcome to the **AI4AI Research Lab**, where we advance the frontiers of safe and interpretable artificial intelligence.

## Our Mission

We are dedicated to developing robust, aligned, and transparent AI systems through cutting-edge research in:

- **AI Alignment & Safety**: Developing frameworks and methodologies for ensuring AI systems behave in accordance with human values and intentions
- **Interpretability**: Understanding neural network behavior through geometric and mechanistic approaches to model transparency
- **Reinforcement Learning**: Exploring RLHF, reward modeling, and off-policy evaluation techniques for robust learning systems
- **Causal Representation Learning**: Investigating causal structures in learned representations for more robust and generalizable AI systems

## Research Philosophy

Our work combines theoretical rigor with practical impact. We believe that understanding the fundamental mechanisms underlying AI behavior is essential for building systems that are both powerful and safe. Through interdisciplinary collaboration and open research, we aim to contribute to the responsible development of artificial intelligence.

## Join Us

We're always interested in collaborating with researchers and students passionate about AI safety and machine learning. Check out our [publications](/publications/) and [projects](/projects/), or reach out via the contact information below.
